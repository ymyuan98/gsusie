[{"path":"https://ymyuan98.github.io/gsusie/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 gsusie authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"get-genotype-data-and-generate-binary-response","dir":"Articles","previous_headings":"","what":"Get genotype data and generate binary response","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"simulate response using genotype data R package named bigsnpr. explanatory variables X example, saved ./data/genotype/genotype-subset-1.rds, subset genotype data containing 2000 successive SNPs 500 individuals. data extracted using following code: set three variables, X83, X1133, X1406, effect variables, non-zero effect size 1 (scaling). , generate linear predictor eta. scale linear combination avoid unexpected large small values eta.","code":"# install.packages(\"bigsnpr\") library(bigsnpr)  `%&%` <- function(a,b) paste0(a,b) data.dir <- \"../data/genotype/\" dir.create(data.dir, recursive=TRUE, showWarnings=FALSE)  .bed.file <- data.dir %&% \"1000G_phase3_common_norel.bed\" if (!file.exists(.bed.file)) {   bigsnpr::download_1000G(data.dir) }  .bk.file <- data.dir %&% \"1000G_phase3_common_norel.rds\" if (!file.exists(.bk.file)){   BED <- snp_readBed(.bed.file) } dat <- snp_attach(.bk.file)$genotypes  nn <- 500 pp <- 2000  set.seed(12345) startpoint <- sample(1 : (ncol(dat)-pp), size = 1) if (nn < 2490) {ii.idx <- sample(1 : 2490, size = nn)} X <- dat[ii.idx, startpoint : (startpoint+pp-1)]  example.data.dir <- \"./example-data/\" saveRDS(X, file = example.data.dir %&% \"genotype-subset-1.rds\") `%&%` <- function(a,b) paste0(a,b) example.data.dir <- \"./example-data/\"  X <- readRDS(example.data.dir %&% \"genotype-subset-1.rds\") nn <- nrow(X)  # 500 pp <- ncol(X)  # 2000  n_effect_vars <- 3 ## effect variables with non-zero effects effect_idx <- c(83, 1133, 1406)  ## effect size (before scaling) effect_size <- rep(1, times = n_effect_vars)  ## linear predictor eta <- scale(X[,effect_idx, drop=F] %*% as.matrix(effect_size))  ## response expit <- function(eta) {   ifelse(eta > 0, 1 / (1 + exp(-eta)), exp(eta) / (1 + exp(eta))) } set.seed(20240220) y <- rbinom(nn, 1, expit(eta))"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"fit-a-logistic-regression-based-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit a logistic regression based GSuSiE model","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"fitting GLM-based GSuSiE model, prefer adding -one column introduce intercept term. practice, inclined add auxiliary column end design matrix X variable indices confusing printing summarized results summary() function. step optional; nevertheless, find , adding -one column, model less likely overfitted. (Wooh!) default, assume 10 effect variables set maxL = min(10, ncol(X)). may choose specify another value maxL. specify fitting logistic regression based GSuSiE model, use argument family = \"binomial\". Correspondingly, gsusie() function call :","code":"library(gsusie) res_gs <- gsusie(cbind(X, 1), y, family = \"binomial\")"},{"path":[]},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Check the variable selection results","what":"Posterior inclusion probabilities","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"print_gsusie_coefficients() function offers 10 (default) variables highest posterior inclusion probabilities (PIPs). default, output 95% credible intervals posterior estimation coefficients.","code":"print_gsusie_coefficients(res_gs) #>  variable    PIP PostMean PostSD CI_lower CI_upper #>      1133 1.0000   1.1635 0.1263   0.9160   1.4111 #>        83 0.7232   0.7434 0.3586   0.0406   1.4462 #>      1406 0.6453   0.8181 0.4488  -0.0615   1.6978 #>      1410 0.3540  -0.4306 0.4236  -1.2608   0.3997 #>        80 0.2739   0.2725 0.3341  -0.3823   0.9273 #>        96 0.0003  -0.0003 0.0104  -0.0207   0.0202 #>      1421 0.0003   0.0002 0.0100  -0.0193   0.0198 #>      1948 0.0003   0.0001 0.0071  -0.0138   0.0141 #>        72 0.0002  -0.0002 0.0078  -0.0154   0.0151 #>      1430 0.0001   0.0001 0.0064  -0.0124   0.0126"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"credible-sets-cs","dir":"Articles","previous_headings":"Check the variable selection results","what":"Credible sets (CS)","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"SuSiE method, output 95% credible sets default. three relevant signals captured 3 credible sets . Effect variables X83 X1406 detected, discovered along another highly-correlated null variable.","code":"print(res_gs$sets) #> $cs #> $cs$L1 #> [1] 1133 #>  #> $cs$L3 #> [1] 80 83 #>  #> $cs$L2 #> [1] 1406 1410 #>  #>  #> $purity #>    min.abs.corr mean.abs.corr mean.abs.corr #> L1    1.0000000     1.0000000     1.0000000 #> L3    0.9931553     0.9931553     0.9931553 #> L2    0.9526977     0.9526977     0.9526977 #>  #> $cs_index #> [1] 1 3 2 #>  #> $coverage #> [1] 1.0000000 0.9970550 0.9992462 #>  #> $requested_coverage #> [1] 0.95"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"graphical-display-of-pips-and-credible-sets","dir":"Articles","previous_headings":"Check the variable selection results","what":"Graphical display of PIPs and credible sets","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"gsusie_plot() function provides plots PIP variable. default, since intercept just auxiliary variable, include plot. case, argument intercept_index needs specified. (P.S. default, set include_intercept = FALSE remove intercept term plot.)   specifying effect_indices, true effect variables colored red. 95% credible sets identified circled different colors.","code":"gsusie_plot(res_gs, y = \"PIP\",              include_intercept = FALSE,              intercept_index = (pp+1),              effect_indices = effect_idx)"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-logistic.html","id":"some-additional-words","dir":"Articles","previous_headings":"","what":"Some additional words","title":"Quick Demo 1: Modelling binary responses via logistic regression based GSuSiE model","text":"may notice, gsusie() function provides option robust estimation. Well… yes. robust approaches package aim -weight impact outliers, .e., extremely big response values, model fitting. approaches effective fitting Poisson regression based GSuSiE model. However, demonstrate comparable advantage logistic regression based GSuSiE model; ’s worse, robust approaches harmful. , unlike count data big numbers may occur, distribution binary response spread ; value binary response just one zero. result, robust estimation unnecessary case.","code":""},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"get-genotype-data-and-generate-count-type-responses","dir":"Articles","previous_headings":"","what":"Get genotype data and generate count-type responses","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"simulate response using genotype data R package named bigsnpr. explanatory variables X example, saved ./data/genotype/genotype-subset-2.rds, subset genotype data containing 2000 successive SNPs 500 individuals. data extracted using following code: Three effect variables randomly selected, non-zero effect size 1 (scaling). , generate linear predictor eta. scale linear combination avoid unexpected large small values eta. histogram synthetic response :  ","code":"# install.packages(\"bigsnpr\") library(bigsnpr)  `%&%` <- function(a,b) paste0(a,b) data.dir <- \"../data/genotype\" dir.create(data.dir, recursive=TRUE, showWarnings=FALSE)  .bed.file <- data.dir %&% \"1000G_phase3_common_norel.bed\" if (!file.exists(.bed.file)) {   bigsnpr::download_1000G(data.dir) }  .bk.file <- data.dir %&% \"1000G_phase3_common_norel.rds\" if (!file.exists(.bk.file)){   BED <- snp_readBed(.bed.file) } dat <- snp_attach(.bk.file)$genotypes  nn <- 500 pp <- 2000  set.seed(123456789) startpoint <- sample(1 : (ncol(dat)-pp), size = 1) if (nn < 2490) {ii.idx <- sample(1 : 2490, size = nn)} X <- dat[ii.idx, startpoint : (startpoint+pp-1)]  example.data.dir <- \"./example-data/\" saveRDS(X, file = example.data.dir %&% \"genotype-subset-2.rds\") `%&%` <- function(a,b) paste0(a,b) example.data.dir <- \"./example-data/\"  X <- readRDS(example.data.dir %&% \"genotype-subset-2.rds\") nn <- nrow(X)  # 500 pp <- ncol(X)  # 2000  n_effect_vars <- 3  set.seed(12345)  ## independent variables with non-zero effects effect_idx <- sample(1:pp, size = n_effect_vars) print(effect_idx) #> [1] 142  51 720  ## effect size effect_size <- rep(1, times = n_effect_vars)  ## linear predictor eta <- scale(X[,effect_idx, drop=F] %*% as.matrix(effect_size))  ## response y <- rpois(nn, exp(eta)) hist(y, breaks = 12)"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"fit-a-poisson-regression-based-gsusie-model","dir":"Articles","previous_headings":"","what":"Fit a Poisson regression based GSuSiE model","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"fitting GLM-based GSuSiE model, prefer adding -one column introduce intercept term. practice, inclined add auxiliary column end design matrix X variable indices confusing printing summarized results summary() function. step optional; nevertheless, find , adding -one column, model less likely overfitted. (Wooh!) default, assume 10 effect variables set maxL = min(10, ncol(X)). may choose specify another value maxL. specify fitting Poisson regression based GSuSiE model, use argument family = \"poisson\". Correspondingly, gsusie() function call :","code":"library(gsusie) res_gs <- gsusie(cbind(X, 1), y, family = \"poisson\")"},{"path":[]},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"posterior-inclusion-probabilities","dir":"Articles","previous_headings":"Check the variable selection results","what":"Posterior inclusion probabilities","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"print_gsusie_coefficients() function offers 10 (default) variables highest posterior inclusion probabilities (PIPs). default, output 95% credible intervals posterior means variable. True effect variables (X51, X142, X720) detected high PIPs. However, null variables X1321 X134 also detected, corresponding PIPs also close 1. Well, result satisfying, two five detected variables effect variables.","code":"print_gsusie_coefficients(res_gs) #>  variable    PIP PostMean PostSD CI_lower CI_upper #>       720 1.0000   1.2171 0.0454   1.1281   1.3060 #>      1321 1.0000   0.2156 0.0798   0.0591   0.3720 #>       142 1.0000   1.0311 0.0296   0.9731   1.0890 #>       134 1.0000   0.0153 0.0619  -0.1060   0.1366 #>        51 1.0000   1.1500 0.0394   1.0727   1.2273 #>       148 0.0025   0.0013 0.0246  -0.0469   0.0496 #>       143 0.0003   0.0001 0.0083  -0.0161   0.0163 #>        54 0.0000   0.0000 0.0047  -0.0092   0.0092 #>       141 0.0000   0.0000 0.0000   0.0000   0.0000 #>       150 0.0000   0.0000 0.0000   0.0000   0.0000"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"credible-sets-cs","dir":"Articles","previous_headings":"Check the variable selection results","what":"Credible sets (CS)","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"SuSiE method, output 95% credible sets default. credible set contain one single variable, two contains null variables X1321 X134.","code":"print(res_gs$sets) #> $cs #> $cs$L1 #> [1] 1321 #>  #> $cs$L2 #> [1] 51 #>  #> $cs$L3 #> [1] 134 #>  #> $cs$L4 #> [1] 720 #>  #> $cs$L6 #> [1] 142 #>  #>  #> $purity #>    min.abs.corr mean.abs.corr mean.abs.corr #> L1            1             1             1 #> L2            1             1             1 #> L3            1             1             1 #> L4            1             1             1 #> L6            1             1             1 #>  #> $cs_index #> [1] 1 2 3 4 6 #>  #> $coverage #> [1] 1.0000000 0.9999780 0.9998448 1.0000000 1.0000000 #>  #> $requested_coverage #> [1] 0.95"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"graphical-display","dir":"Articles","previous_headings":"Check the variable selection results","what":"Graphical Display","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"gsusie_plot() function provides plots PIP variable. default, since intercept just auxiliary variable, include plot. case, argument intercept_index needs specified. (P.S. default, set include_intercept = FALSE remove intercept term plot.)   specifying effect_indices, true effect variables colored red. 95% credible sets identified circled different colors. plot also vividly presents null variables X1321 `X134 mistakenly selected high PIPs. Therefore, hope address false discoveries.","code":"gsusie_plot(res_gs, y = \"PIP\",              include_intercept = FALSE,              intercept_index = (pp+1),              effect_indices = effect_idx)"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"refine-a-poisson-regression-based-gsusie-model-via-robust-estimation","dir":"Articles","previous_headings":"","what":"Refine a Poisson regression based GSuSiE model via robust estimation","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"know, count data (response) usually contains extremely large values. unexpected values may affect model fitting, resulting false discoveries even failure fit model. Hence, suggest robust estimation modelling Poisson regression based GSuSiE model. gsusie function provides several robust estimation approaches. Based experience simulation experiments, recommend Huber reweighting method, , iteration, reweights data point Huber weight(Huber 1964) according residual updated previous iteration (M-estimation). corresponding function call :","code":"res_gs_hb <- gsusie(cbind(X, 1), y, family = \"poisson\",                      robust_estimation = TRUE,                     robust_method = \"huber\")"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"check-the-refined-variable-selection-results","dir":"Articles","previous_headings":"Refine a Poisson regression based GSuSiE model via robust estimation","what":"Check the refined variable selection results","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"fitted results well graphical display :   , notice , applying robust Huber reweighting method, selection accuracy somehow improved: PIPs X1321 X134 longer deviate 0 thus able falsely discovered. Instead, null variable X54 detected along true effect variable X51, PIP former relatively lower latter. Besides, suggested , X51 captured two different credible sets, one contains X51. may indicate X51 likely important X54. Well, , refined results least gratifying unrefined ones. performing Huber reweighting via M-estimation procedures, also provide option Huber reweighting via S-estimation(Rousseeuw Yohai 1984). corresponding function call : fitted results well graphical display :   simulation experiments, results yielded Huber reweighting via M- S-estimation procedures alike. previous experience suggests Bisquare reweighting method usually conservative offer much informative information Huber reweighting method. recommend simply removing proportion data points whose pseudo-weights pseudo-residuals exceed certain threshold, difficult tell whether specific threshold appropriate .","code":"print_gsusie_coefficients(res_gs_hb) #>  variable    PIP PostMean PostSD CI_lower CI_upper #>       720 1.0000   1.2238 0.0451   1.1354   1.3123 #>       142 1.0000   1.0320 0.0298   0.9737   1.0904 #>        51 1.0000   0.8946 0.1623   0.5765   1.2128 #>        54 0.7108  -0.3032 0.1672  -0.6309   0.0244 #>        55 0.0000   0.0000 0.0000   0.0000   0.0000 #>        53 0.0000   0.0000 0.0000   0.0000   0.0000 #>      2001 0.0000   0.0000 0.0000   0.0000   0.0000 #>       150 0.0000   0.0000 0.0000   0.0000   0.0000 #>       123 0.0000   0.0000 0.0000   0.0000   0.0000 #>       152 0.0000   0.0000 0.0000   0.0000   0.0000 summary(res_gs_hb) #>  #> Variables in credible sets: #>  #>  variable variable_prob cs #>       720     1.0000000  4 #>       142     1.0000000  2 #>        51     0.9999941  3 #>        54     0.7107968  3 #>  #> Credible sets summary: #>  #>  cs cs_loge_abf cs_avg_r2 cs_min_r2 variable #>   1   131.74824 1.0000000 1.0000000       51 #>   2   286.25426 1.0000000 1.0000000      142 #>   4    58.45426 1.0000000 1.0000000      720 #>   3    30.45770 0.8725642 0.8725642    51,54 print(res_gs_hb$sets) #> $cs #> $cs$L1 #> [1] 51 #>  #> $cs$L2 #> [1] 142 #>  #> $cs$L4 #> [1] 720 #>  #> $cs$L3 #> [1] 51 54 #>  #>  #> $purity #>    min.abs.corr mean.abs.corr mean.abs.corr #> L1    1.0000000     1.0000000     1.0000000 #> L2    1.0000000     1.0000000     1.0000000 #> L4    1.0000000     1.0000000     1.0000000 #> L3    0.9341115     0.9341115     0.9341115 #>  #> $cs_index #> [1] 1 2 4 3 #>  #> $coverage #> [1] 0.9999917 1.0000000 1.0000000 1.0000000 #>  #> $requested_coverage #> [1] 0.95 gsusie_plot(res_gs_hb, y = \"PIP\",              include_intercept = FALSE,              intercept_index = (pp+1),              effect_indices = effect_idx) res_gs_hb2 <- gsusie(cbind(X, 1), y, family = \"poisson\",                       robust_estimation = TRUE,                       robust_method = \"huber\",                       robust_tuning_method = \"S\") print_gsusie_coefficients(res_gs_hb2) #>  variable    PIP PostMean PostSD CI_lower CI_upper #>       720 1.0000   1.2209 0.0639   1.0955   1.3462 #>       142 1.0000   1.0400 0.0420   0.9577   1.1223 #>        51 0.9662   0.9021 0.2870   0.3396   1.4646 #>        54 0.4280  -0.2771 0.2880  -0.8415   0.2873 #>       150 0.0000   0.0000 0.0008  -0.0015   0.0015 #>      2001 0.0000   0.0000 0.0000  -0.0001   0.0001 #>        53 0.0000   0.0000 0.0000   0.0000   0.0000 #>        55 0.0000   0.0000 0.0000   0.0000   0.0000 #>      1511 0.0000   0.0000 0.0000   0.0000   0.0000 #>       440 0.0000   0.0000 0.0000   0.0000   0.0000 summary(res_gs_hb2) #>  #> Variables in credible sets: #>  #>  variable variable_prob cs #>       720     1.0000000  4 #>       142     0.9999989  2 #>        51     0.9662311  1 #>        54     0.4279796  1 #>  #> Credible sets summary: #>  #>  cs cs_loge_abf cs_avg_r2 cs_min_r2 variable #>   2   141.07966 1.0000000 1.0000000      142 #>   4    24.27865 1.0000000 1.0000000      720 #>   1    30.77141 0.8725642 0.8725642    51,54 gsusie_plot(res_gs_hb2, y = \"PIP\",              include_intercept = FALSE,              intercept_index = (pp+1),              effect_indices = effect_idx)"},{"path":"https://ymyuan98.github.io/gsusie/articles/gsusie-poisson.html","id":"suggestions-for-preprocessing-count-type-responses","dir":"Articles","previous_headings":"","what":"Suggestions for preprocessing count-type responses","title":"Quick Demo 2: Modelling count-type responses via Poisson regression based GSuSiE model","text":"Two cases count data response may result difficulty fitting Poisson regression based GSuSiE model. One presence many zeros, existence unexpectedly large values. former can addressed fitting zero-inflated Poisson negative binomial regression model; however, GSuSiE versions two genearlized linear models yet developed gsusie package. latter may lead unexpected failure fitting GSuSiE model, extreme values may lead overflow certain fitting procedure. simple approach simultaneously address problems preprocess response: scale response without changing shape original distribution. Specifically, following transformation operated new \\(y\\) plugged gsusie function fit GSuSiE model. transformation \\(y\\) particularly beneficial reducing chance failure model fitting.","code":"y <- exp(log1p(y))"},{"path":[]},{"path":"https://ymyuan98.github.io/gsusie/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ming Yuan. Author, maintainer.","code":""},{"path":"https://ymyuan98.github.io/gsusie/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Yuan M (2024). gsusie: Generalized Sum Single-Effects Models. https://github.com/ymyuan98/gsusie, https://ymyuan98.github.io/gsusie/.","code":"@Manual{,   title = {gsusie: Generalized Sum of Single-Effects Models},   author = {Ming Yuan},   year = {2024},   note = {https://github.com/ymyuan98/gsusie, https://ymyuan98.github.io/gsusie/}, }"},{"path":"https://ymyuan98.github.io/gsusie/index.html","id":"gsusie-package","dir":"","previous_headings":"","what":"Generalized Sum of Single-Effects Models","title":"Generalized Sum of Single-Effects Models","text":"gsusie package implements Generalized Sum Single-Effects (GSuSiE) model. Developed Sum Single-Effects (SuSiE) model Wang et al. (2020) performs variable selection linear regression models, GSuSiE model expands usage allowing select variables generalized linear models (GLMs) logistic Poisson regressions. words, gsusie function can model binary count type responses. Likewise, method particularly compatible high-dimensional settings high correlation exists among explanatory variables X, number true effect variables much smaller total number explanatory variables (.e., sparse variable selection). Yet, can also effective scenarios. method provides summaries posterior inclusion probabilities (PIPs) credible sets make inferences variables selected. Additionally, robust estimations provided avoid potential effect outliers model fitting. adapted iterative Bayesian Stepwise Selection (IBSS) algorithm combined iterative reweighted least squared (IRLS) approach address GLMs robust estimation.","code":""},{"path":"https://ymyuan98.github.io/gsusie/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Generalized Sum of Single-Effects Models","text":"install R package directly Github:","code":"# install.packages(\"devtools\") devtools::install_github(\"ymyuan98/gsusie\")"},{"path":"https://ymyuan98.github.io/gsusie/reference/check_abnormal_subjects.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensitivity check — check_abnormal_subjects","title":"Sensitivity check — check_abnormal_subjects","text":"iterative weighted least square methods, data point transformed corresponding pseudo-response corresponding pseudo-variance. transformations inevitably point abnormal subjects whose pseudo-response pseudo-variance abnormal value, Inf/-Inf NaN(?). take subjects abnormal pseudo-response/pseudo-variance “abnormal subjects”. check_abnormal_subjects() return indices abnormal subjects ().","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/check_abnormal_subjects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensitivity check — check_abnormal_subjects","text":"","code":"check_abnormal_subjects(values)"},{"path":"https://ymyuan98.github.io/gsusie/reference/check_abnormal_subjects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sensitivity check — check_abnormal_subjects","text":"values vector length n, check whether contains Inf NAN.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/check_abnormal_subjects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sensitivity check — check_abnormal_subjects","text":"index vector named abn_idx values[abn_idx] either Inf NAN.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_colstats.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxilary computation functions — compute_colstats","title":"Auxilary computation functions — compute_colstats","text":"file defines auxiliary computation functions.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_colstats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auxilary computation functions — compute_colstats","text":"","code":"compute_colstats(X, scale = TRUE)"},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_colstats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Auxilary computation functions — compute_colstats","text":"scale Boolean, indicator perform standardization . Call scale = TRUE compute column-wise means standard deviations (sd). scale = FALSE, output mean sd vectors , respectively, -0 -1 vector length equal number columns \\(X\\). returns list two attributes: $cm p-vector column-wise means X scale=TRUE, p-dim vector zeros otherwise; $csd p-dim vector column-wise standard deviations X scale=TRUE, p-dim vector ones otherwise; compute_Xb offers matrix multiplication (n x p) matrix X (p x 1) array/matrix b. output (n x 1) matrix.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_colstats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Auxilary computation functions — compute_colstats","text":"compute_colstats computes mean standard deviation column.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_logw2_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_logw2_logistic computes the log-pseudo-variance\nfor each observation — compute_logw2_logistic","title":"compute_logw2_logistic computes the log-pseudo-variance\nfor each observation — compute_logw2_logistic","text":"compute_logw2_logistic computes log-pseudo-variance observation","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_logw2_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_logw2_logistic computes the log-pseudo-variance\nfor each observation — compute_logw2_logistic","text":"","code":"compute_logw2_logistic(eta)"},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_logw2_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions related to Poisson regression model with log link — compute_logw2_poisson","title":"Functions related to Poisson regression model with log link — compute_logw2_poisson","text":"file defines functions related Poisson regression model logistic link, including (log ) pseudo-variance pseudo-response needed calculated iterative fitting (approximated) weighted linear regression model, exact approximated log-likelihood. functions output vectors length y #' compute_logw2_poisson computes log-pseudo-variance","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_logw2_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions related to Poisson regression model with log link — compute_logw2_poisson","text":"","code":"compute_logw2_poisson(eta)"},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_psdresponse_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_psdresponse_logistic computes the pseudo-response\nfor each observation — compute_psdresponse_logistic","title":"compute_psdresponse_logistic computes the pseudo-response\nfor each observation — compute_psdresponse_logistic","text":"compute_psdresponse_logistic computes pseudo-response observation","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/compute_psdresponse_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_psdresponse_logistic computes the pseudo-response\nfor each observation — compute_psdresponse_logistic","text":"","code":"compute_psdresponse_logistic(eta, y)"},{"path":"https://ymyuan98.github.io/gsusie/reference/elbo.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Evidence of Lower Bounds (ELBO) — KL_prior_v_post","title":"Compute Evidence of Lower Bounds (ELBO) — KL_prior_v_post","text":"function compute second part ELBO lth WSER model ELBO = Expected loglik + KL(g(b)||q(b)). Compute (estimated) ELBO overall model. Clip inputs avoid feeding 0 log()","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/elbo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Evidence of Lower Bounds (ELBO) — KL_prior_v_post","text":"","code":"KL_prior_v_post(sigma02, pie, alpha, mu, sigma12)  get_objective(X, y, gs, model, abn.rm = FALSE)  clipped(values, tol = 1e-16)"},{"path":"https://ymyuan98.github.io/gsusie/reference/elbo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Evidence of Lower Bounds (ELBO) — KL_prior_v_post","text":"sigma02 scalar, prior variance coefficient pie p-dim vector prior inclusion probabilities alpha p-dim vector posterior inclusion probabilities mu p-dim vector posterior means sigma12 p-dim vector posterior variances","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/elbo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Evidence of Lower Bounds (ELBO) — KL_prior_v_post","text":"value KL-divergence prior posterior (VA) distributions L WSER models.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/expit.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions related to binomial model with logistic link — expit","title":"Functions related to binomial model with logistic link — expit","text":"file defines functions related binomial model logistic link, including (log ) pseudo-variance pseudo-response needed calculated iterative fitting (approximated) weighted linear regression model, exact approximated log-likelihood. functions output vectors length y","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/expit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions related to binomial model with logistic link — expit","text":"","code":"expit(eta)"},{"path":"https://ymyuan98.github.io/gsusie/reference/get_cs_correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Correlations Between CSs, using Variable with Maximum PIP From Each CS — get_cs_correlation","title":"Get Correlations Between CSs, using Variable with Maximum PIP From Each CS — get_cs_correlation","text":"function evaluates correlation single effect CSs. part SuSiE inference. Rather, designed diagnostic tool assess correlated reported CS .","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/get_cs_correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Correlations Between CSs, using Variable with Maximum PIP From Each CS — get_cs_correlation","text":"","code":"get_cs_correlation(res, X = NULL, Xcorr = NULL, max = FALSE)"},{"path":"https://ymyuan98.github.io/gsusie/reference/get_cs_correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Correlations Between CSs, using Variable with Maximum PIP From Each CS — get_cs_correlation","text":"res SuSiE fit, typically output susie one variants. X n p matrix values p variables (covariates) n samples. provided, correlation variables computed used remove CSs whose minimum correlation among variables smaller min_abs_corr. Xcorr p p matrix correlations variables (covariates). provided, used remove CSs whose minimum correlation among variables smaller min_abs_corr. max Max = FAFLSE, return matrix CS correlations. Max = TRUE, return maximum absolute correlation among pairs correlations.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/get_cs_correlation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Correlations Between CSs, using Variable with Maximum PIP From Each CS — get_cs_correlation","text":"matrix correlations CSs, maximum absolute correlation max = TRUE.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Sum of Single-effects (GSuSiE) — gsusie","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"Performs sparse Bayesian variable selection generalized linear models using genaralized sum single-effects (GSuSiE) model. function currently designed Poisson logistic regression models, response y can count type binary variable. Codes well arguments descriptions referred https://github.com/stephenslab/susieR/blob/master/R/susie.R. brief, function transforms GLMs iterative reweighted least square problems, (iteration) tries find regression coefficients \\(\\beta\\) log-likelihood function \\(\\ell(X,y|\\beta,\\nu^2)=-\\frac{1}{2}\\sum_{=1}^n\\left(\\frac{z_i-x_{.} \\beta}{\\nu}\\right)^2\\) maximized. Following “susie assumptions”, \\(\\beta = \\sum_{l=1}^L \\beta_l\\), \\(\\beta_l\\) vector length p one non-zero element. value \\(maxL\\) fixed value reasonable upper bound number non-zero effects detected.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"","code":"gsusie(   X,   y,   family = c(\"binomial\", \"poisson\"),   maxL = min(10, ncol(X)),   prior_inclusion_prob = NULL,   estimate_prior_variance = TRUE,   estimate_prior_method = c(\"optim\", \"EM\", \"simple\"),   coef_prior_variance = 1,   check_null_threshold = 0,   prior_tol = 1e-09,   robust_estimation = FALSE,   robust_method = c(\"huber\", \"simple\", \"bisquare\"),   simple_outlier_fraction = NULL,   simple_outlier_thres = NULL,   robust_tuning_method = c(\"M\", \"S\"),   null_weight = 0,   standardize = TRUE,   coverage = 0.95,   min_abs_corr = 0.5,   max_iters = 100,   na.rm = FALSE,   tol = 0.01,   n_purity = 100,   abnormal_proportion = 0.5,   track_fit = FALSE,   verbose = FALSE )"},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"X n p matrix covariates. y observed responses, vector length n. family description error distribution link function used model. far, binomial distributions logit link (family=\"binomial\") Poisson distributions log link (family=\"poisson\") developed. maxL Maximum number non-zero effects gsusie model. default, maxL=10. number covariates, p, greater 10, set maxL=p. prior_inclusion_prob vector length p, entry gives prior probability corresponding column X nonzero effect outcome, y. estimate_prior_variance Boolean. TRUE, coefficient prior variance estimated coef_prior_variance used initial value optimization (provided). FALSE, prior variance maxL effects fixed determined value supplied coef_prior_variance. estimate_prior_method method used estimating prior variance. estimate_prior_method=\"simple\" used, likelihood specified prior variance compared likelihood variance zero, setting larger likelihood retained. coef_prior_variance NULL, scalar specifying prior variance coefficient, vector length maxL. scalar, value consistent \\(\\beta_l\\). check_null_threshold prior variance estimated, compare estimated null, set prior variance zero unless log-likelihood using estimate larger threshold amount. example, set check_null_threshold = 0.1, \"nudge\" estimate towards zero difference log-likelihoods small. note caution setting value greater zero may lead IBSS fitting procedure occasionally decrease ELBO. prior_tol prior variance estimated, compare estimated value prior_tol end computation, exclude single effect PIP computation estimated prior vairnace smaller tolerance value. robust_estimation robust_estimation=TRUE, robust estimation method applied coefficient estimation. robust_method robust_method= \"simple\", outliers defined simple_outlier_fraction simple_outlier_thres simply removed iteration. robust_method=\"huber\", Huber weights additionally multiplied pseudo-weights iteration. robust_method = \"bisquare\", (Tukey's) bisquare weights additionally multipled pseudo-weights iteration. simple_outlier_fraction value 0 1, indicating fraction outliers: define simple_outlier_fraction percent subjects highest absolute values (inverse pseudo-variance) outliers. default, simple_outlier_fraction=NULL set outlier fraction. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". simple_outlier_thres real value, indicating outliers whose inverse pseudo-variance exceed threshold removed current iteration. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". robust_tuning_method robust_tuning_method = \"M\", M-estimation performed. robust_tuning_method = \"S\", S-estimation performed. argument specifies tuning method, .e., method defining outliers iteration, applying Huber Bisquare reweighting method (robust_method = \"huber\" robust_method = \"bisquare\"). null_weight Prior probability effect (number 0 1, exactly 1). standardize standardize = TRUE, standardize columns X unit variance prior fitting (equivalently standardize XtX Xty effect). column X zero variance standardized. coverage number 0 1 specifying “coverage” estimated confidence sets. min_abs_corr Minimum absolute correlation allowed credible set. default, 0.5, corresponds squared correlation 0.25, commonly used threshold genotype data genetic studies. max_iters Maximum number iterations. na.rm Drop missing values y X y. tol small, non-negative number specifying convergence tolerance IBSS fitting procedure. fitting procedure halt difference variational lower bound, “ELBO” (objective function maximized), less tol. n_purity Passed argument n_purity gsusie_get_cs. abnormal_proportion value 0 1. Abnormal data point may arise transforming GLM (iterative re)weighted least square problems. Currently, abnormal points data points whose pseudo-variances pseudo-responses Inf NAN. abnormal point detected, removed current iteration. number detected abnormal subjects exceeds abnormal_proportion * nrow(X), stop fitting model. track_fit track_fit=TRUE, trace also returned containing detailed information estimates iteration IBSS fitting procedure. verbose verbose=TRUE, algorithm's progress, summary optimization settings, printed console.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"\"gsusie\" object following elements: alpha maxL p matrix posterior inclusion probabilities. mu maxL p matrix posterior means, conditional inclusion. mu2 maxL p matrix posterior second moments, conditional inclusion. lbf Log-Bayes Factor single effect. lbf_variable Log-Bayes Factor variable single effect. family generalized linear model family, either “binomial” “poisson”. Xr vector length n, equal X %*% colSums(alpha   * mu). V Prior variance non-zero elements \\(\\beta\\). converged TRUE FALSE indicating whether IBSS converged solution within chosen tolerance level. elbo value variational lower bound, “ELBO”, achieved iteration IBSS fitting procedure. loglik_exact value exact log-likelihood function GLM. loglik_apprx value approximated log-likelihood function weighted least square model transformed corresponding GLM. niter Number IBSS iterations performed. sets Credible sets estimated model fit. pip vector length p giving marginal posterior inclusion probabilities p covariates. X_column_scale_factor vector length p giving scale factor column. X_column_center_factor vector length p giving center factor column","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"fit GSuSiE Poisson regression model, recommended perform robust estimation. robust estimation helps address potential negative effect outliers especially count data. M/S-estimation Huber weights suggested (setting robust_estimation=TRUE, robust_method=\"huber\", robust_tuning_method=\"M\". fit GSuSiE logistic regression model, recommended perform robust estimation (default robust_estimation=FALSE).","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"G. Wang, . Sarkar, P. Carbonetto M. Stephens (2020). simple new approach variable selection regression, application genetic fine-mapping. Journal Royal Statistical Society, Series B 82, 1273-1300 doi:10.1101/501114 .","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Sum of Single-effects (GSuSiE) — gsusie","text":"","code":"## A Poisson regression case ------------------------------------------------ if (FALSE) { set.seed(20231130)  # Generative data model nn <- 1000 pp <- 10 X <- matrix(rnorm(nn * pp), ncol = pp) X[,1:2] <- MASS::mvrnorm(nn, mu = c(0,0),                        Sigma = matrix(c(1, 0.8, 0.8, 1), nrow = 2)) X[,5:7] <- MASS::mvrnorm(nn, mu = rep(0, 3),                        Sigma = matrix(c(1, 0.6, 0.9,                                         0.6, 1, 0.75,                                         0.9, 0.75, 1),                                        nrow = 3, byrow = TRUE)) effect_idx <- c(1, 6) Eta <- scale(X[,effect_idx, drop=FALSE] %*% as.matrix(c(-2, 0.2))) y <- rpois(nn, exp(Eta)) plot(y) plot(exp(scale(log1p(y))))  ## Vanilla G-SuSiE # res_gs <- gsusie(cbind(X, 1), y, family = \"poisson\") res_gs <- gsusie(cbind(X, 1), exp(scale(log1p(y))), family = \"poisson\") summary(res_gs) print_gsusie_coefficients(res_gs)  ## Robust G-SuSiE for Poisson regression # res_gs <- gsusie(cbind(X, 1), y, family = \"poisson\", #                 robust_estimation = TRUE, robust_method = \"huber\", #                 robust_tuning_method = \"M\") res_gs <- gsusie(cbind(X, 1), exp(scale(log1p(y))), family = \"poisson\",                  robust_estimation = TRUE, robust_method = \"huber\",                  robust_tuning_method = \"M\") summary(res_gs) print_gsusie_coefficients(res_gs) }   ## A logistic regression case ----------------------------------------------- if (FALSE) { #' set.seed(20240103) # Generative data model nn <- 1000 pp <- 10 X <- matrix(rnorm(nn * pp), ncol = pp)  effect_idx <- c(1, 6) bb <- rnorm(2) Eta <- scale(X[,effect_idx, drop=FALSE] %*% as.matrix(bb)) expit <- function(eta) {   ifelse(eta > 0, 1 / (1 + exp(-eta)), exp(eta) / (1 + exp(eta))) } y <- rbinom(nn, 1, expit(Eta)) ## Vanilla GSuSiE for logistic regression res_gs <- gsusie(X, y, family = \"binomial\") summary(res_gs) print_gsusie_coefficients(res_gs) }"},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_get_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Inferences From Fitted G-SuSiE/SuSiE Model — gsusie_get_objective","title":"Inferences From Fitted G-SuSiE/SuSiE Model — gsusie_get_objective","text":"functions access basic properties draw inference fitted susie/gsusie model. codes descriptions copied https://github.com/stephenslab/susieR/blob/master/R/susie_utils.R","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_get_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inferences From Fitted G-SuSiE/SuSiE Model — gsusie_get_objective","text":"","code":"gsusie_get_objective(res, last_only = TRUE, warning_tol = 1e-06)  gsusie_get_log_pseudo_variance(res, X = NULL, scale = TRUE)  gsusie_get_posterior_mean(res, prior_tol = 1e-09)  gsusie_get_posterior_sd(res, prior_tol = 1e-09)  gsusie_get_niter(res)  gsusie_get_prior_variance(res)  gsusie_get_lfsr(res)  gsusie_get_posterior_samples(res, num_samples)  gsusie_get_cs(   res,   X = NULL,   Xcorr = NULL,   coverage = 0.95,   min_abs_corr = 0.5,   dedup = TRUE,   squared = FALSE,   check_symmetric = TRUE,   n_purity = 100 )  gsusie_get_pip(res, prune_by_cs = FALSE, prior_tol = 1e-09)"},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_get_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inferences From Fitted G-SuSiE/SuSiE Model — gsusie_get_objective","text":"res susie fit, output susie gsusie. last_only last_only = FALSE, return ELBO iterations; otherwise return ELBO last iteration . warning_tol Warn ELBO decreasing tolerance level. X n p matrix values p variables (covariates) n samples. provided, correlation variables computed used remove CSs whose minimum correlation among variables smaller min_abs_corr. scale Boolean, indicates whether input X needs scaled . prior_tol Filter effects estimated prior variance smaller threshold. num_samples number draws posterior distribution. Xcorr p p matrix correlations variables (covariates). provided, used remove CSs whose minimum correlation among variables smaller min_abs_corr. coverage number 0 1 specifying desired coverage CS. min_abs_corr \"purity\" threshold CS. CS contains pair variables correlation less threshold filtered reported. dedup dedup = TRUE, remove duplicate CSs. squared squared = TRUE, report min, mean median squared correlation instead absolute correlation. check_symmetric check_symmetric = TRUE, perform check symmetry matrix Xcorr Xcorr provided (NULL). n_purity maximum number credible set (CS) variables used calculating correlation (“purity”) statistic. number variables included CS greater number, CS variables randomly subsampled. prune_by_cs Whether ignore single effects reported CS calculating PIP.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_get_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inferences From Fitted G-SuSiE/SuSiE Model — gsusie_get_objective","text":"gsusie_get_objective returns evidence lower bound (ELBO) achieved fitted susie model , optionally, iteration IBSS fitting procedure.cs gsusie_get_prior_variance returns (estimated fixed) prior variance parameters. gsusie_get_posterior_mean returns posterior mean regression coefficients fitted susie model. gsusie_get_posterior_sd returns posterior standard deviation coefficients fitted susie model. gsusie_get_niter returns number model fitting iterations performed. gsusie_get_pip returns vector containing posterior inclusion probabilities (PIPs) variables. gsusie_get_lfsr returns vector containing average lfsr across variables single-effect, weighted posterior inclusion probability (alpha). gsusie_get_posterior_samples returns list containing effect sizes samples causal status two components: b, num_variables x num_samples matrix effect sizes; gamma, num_variables x num_samples matrix causal status random draws. gsusie_get_cs returns credible sets (CSs) susie fit, well summaries correlation among variables included CS. desired, one can filter CSs meet specified “purity” threshold; , either X Xcorr must supplied. returns list following elements: cs list list element vector containing indices variables CS. coverage nominal coverage specified CS. purity X Xcorr iis provided), purity CS. cs_index X Xcorr provided) index (number 1 L) reported CS supplied susie fit.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"G-SuSiE Plots. — gsusie_plot","title":"G-SuSiE Plots. — gsusie_plot","text":"gsusie_plot produces per-variable summary G-SuSiE credible sets.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"G-SuSiE Plots. — gsusie_plot","text":"","code":"gsusie_plot(   model,   y,   include_intercept = FALSE,   intercept_index = NULL,   effect_indices = NULL,   add_bar = FALSE,   pos = NULL,   max_cs = 400,   add_legend = NULL,   ... )"},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"G-SuSiE Plots. — gsusie_plot","text":"model SuSiE G-SuSiE fit, typically output gsusie one variants. gsuse_plot, susie fit must model$z(?), model$PIP, may include model$sets. model may also vector z-scores PIPs. y string indicating plot: either \"z_original\" z-scores, \"z\" z-score derived p-values (base-10) log-scale, \"PIP\" posterior inclusion probabilities, \"log10PIP\" posterior inclusion probabiliities (base-10) log-scale. setting, data plotted . include_intercept Boolean. include_intercept = FALSE, intercept term removed plot; index intercept specified intercept_index. intercept_index numeric number specifying index intercept. required include_intercept=FALSE (default). effect_indices numeric vector indices effect variables. points highlighted red. add_bar add_bar = TRUE, add horizontal bar signals credible interval. pos can either (1) numeric vector indices subset variables plot, (2) list following list elements: pos$attr, pos$start pos$end, pos$attr character string name index variable model object, pos$start pos$end boundaries indices plot. See provided examples. max_cs largest credible set display, either based purity (set max_cs 0 1), based size (set max_cs > 1). add_legend add_legend = TRUE, add legend annotate size purity CS discovered. can also specified location legends added, e.g., add_legend = \"bottomright\" (default location \"topright\"). ... Additional arguments passed plot.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/gsusie_plots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"G-SuSiE Plots. — gsusie_plot","text":"Invisibly returns NULL.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/init_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize a GSuSiE object using regression coefficients — init_setup","title":"Initialize a GSuSiE object using regression coefficients — init_setup","text":"Initialize GSuSiE object using regression coefficients","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/init_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize a GSuSiE object using regression coefficients — init_setup","text":"","code":"init_setup(   n,   p,   L,   family,   prior_inclusion_prob,   coef_prior_variance,   null_weight )"},{"path":"https://ymyuan98.github.io/gsusie/reference/neg.optimfunc.logscale.html","id":null,"dir":"Reference","previous_headings":"","what":"The following is the negative of the objective function — neg.optimfunc.logscale","title":"The following is the negative of the objective function — neg.optimfunc.logscale","text":"following negative objective function","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/neg.optimfunc.logscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The following is the negative of the objective function — neg.optimfunc.logscale","text":"","code":"neg.optimfunc.logscale(lV, betahat, shat2, prior_inclusion_prob)"},{"path":"https://ymyuan98.github.io/gsusie/reference/optimfunc.logscale.html","id":null,"dir":"Reference","previous_headings":"","what":"The following is the log-scale of the optimization goal\nas a function of prior variance V. — optimfunc.logscale","title":"The following is the log-scale of the optimization goal\nas a function of prior variance V. — optimfunc.logscale","text":"following log-scale optimization goal function prior variance V.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/optimfunc.logscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The following is the log-scale of the optimization goal\nas a function of prior variance V. — optimfunc.logscale","text":"","code":"optimfunc.logscale(V, betahat, shat2, prior_inclusion_prob)"},{"path":"https://ymyuan98.github.io/gsusie/reference/optimize_prior_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate prior variance — optimize_prior_variance","title":"Estimate prior variance — optimize_prior_variance","text":"function, betahat represents MLE, shat2 represents corresponding variance.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/optimize_prior_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate prior variance — optimize_prior_variance","text":"","code":"optimize_prior_variance(   optimize_V,   betahat,   shat2,   prior_inclusion_prob,   alpha = NULL,   post_mean2 = NULL,   V_init = NULL,   check_null_threshold = 0 )"},{"path":"https://ymyuan98.github.io/gsusie/reference/print_gsusie_coefficients.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize posterior estimations of regression coefficients — print_gsusie_coefficients","title":"Summarize posterior estimations of regression coefficients — print_gsusie_coefficients","text":"function returns, default, top_n=10 coefficients highest PIPs, sorted decreasing order.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/print_gsusie_coefficients.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize posterior estimations of regression coefficients — print_gsusie_coefficients","text":"","code":"print_gsusie_coefficients(   object,   subset_vars = NULL,   decreasing = TRUE,   top_n = 10,   cred_int = TRUE,   coverage = 0.95,   digits = 4 )"},{"path":"https://ymyuan98.github.io/gsusie/reference/print_gsusie_coefficients.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize posterior estimations of regression coefficients — print_gsusie_coefficients","text":"object gsusie fit subset_vars array numeric indices variable names presented output. var_names = NULL, default output contains coefficients variables ncol(X)<= 10 top_n variables highest PIPs ncol(X) > 10. decreasing logical, whether list variables decreasing order PIP values. top_n numeric, number coefficients displayed. default top_n=min(10, length(object$pip)). cred_int logical, whether return equal-tailed credible intervals coverage numeric, 0 1, coverage probability credible intervals. digits integer indicating number decimal places used. digits == NULL, output rounded.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/print_gsusie_coefficients.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize posterior estimations of regression coefficients — print_gsusie_coefficients","text":"function outputs data.frame top_n variables highest PIPs, variables specified vars. Variables sorted decreasing order PIP values. data.frame contains variable name, PIP, posterior mean (PostMean), posterior sd (PostSD), , cred_int=TRUE, credible interval (CI_lower CI_upper) variable.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/remove_abnormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove abnormal points from the current matrix/array — remove_abnormal","title":"Remove abnormal points from the current matrix/array — remove_abnormal","text":"Remove abnormal points current matrix/array","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/remove_abnormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove abnormal points from the current matrix/array — remove_abnormal","text":"","code":"remove_abnormal(abn_index, object)"},{"path":"https://ymyuan98.github.io/gsusie/reference/remove_abnormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove abnormal points from the current matrix/array — remove_abnormal","text":"abn_index array indices abnormal points. object matrix vector may contain abnormal points. object matrix, abn_index indicates rows removed.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/robust_importance_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust estimations — robust_importance_weights","title":"Robust estimations — robust_importance_weights","text":"fitting generalized linear model, outliers, .e. unexpected values, may occur observations intermediate procedures, weights (.e. inverse pseudo-variance) pseudo-responses. Hence, robust estimations considered \"-weigh\" influential points.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/robust_importance_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust estimations — robust_importance_weights","text":"","code":"robust_importance_weights(   values,   robust_method = c(\"none\", \"huber\", \"simple\", \"bisquare\"),   simple_outlier_fraction = NULL,   simple_outlier_thres = NULL,   robust_tuning_method = c(\"M\", \"S\"),   previous_imp_weights = NULL )"},{"path":"https://ymyuan98.github.io/gsusie/reference/robust_importance_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust estimations — robust_importance_weights","text":"values vector may contains outliers. May weights (inverse pseudo-variance) residuals(?!) robust_method method = \"none\", subjects included coefficient estimation. method = \"simple\", outliers defined simple_outlier_fraction simple_outlier_thres exlucded current iteration coefficient estimation. method = \"huber\", huber weights assigned subject based “pseudo-residuals” rr. simple_outlier_fraction value 0 1, indicating fraction outliers: define simple_outlier_fraction percent subjects highest absolute values (inverse pseudo-variance) outliers. default, simple_outlier_fraction=NULL set outlier fraction. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". simple_outlier_thres real value, indicating outliers whose inverse pseudo-variance exceed threshold removed current iteration. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". robust_tuning_method robust_tuning_method = \"M\", M-estimation performed. robust_tuning_method = \"S\", S-estimation performed. argument specifies tuning method, .e., method defining outliers iteration, applying Huber Bisquare reweighting method (robust_method = \"huber\" robust_method = \"bisquare\"). previous_imp_weights importance weights previous iteration, used calculate importance weights current iteration S-estimation. previous_imp_weights NULL, indicates first iteration, thus S-estimation need initialized.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/robust_importance_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust estimations — robust_importance_weights","text":"imp_weights vector length n, importance weights. subject removed current iteration, importance weights 0.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/summary.gsusie.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize G-SuSiE Fit. — summary.gsusie","title":"Summarize G-SuSiE Fit. — summary.gsusie","text":"summary method “gsusie” class Almost https://github.com/stephenslab/susieR/blob/master/R/summary.susie.R, except change output class \"summary.gsusie\".","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/summary.gsusie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize G-SuSiE Fit. — summary.gsusie","text":"","code":"# S3 method for gsusie summary(object, ...)  # S3 method for summary.gsusie print(x, ...)"},{"path":"https://ymyuan98.github.io/gsusie/reference/summary.gsusie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize G-SuSiE Fit. — summary.gsusie","text":"object GSuSiE fit ... Additional arguments passed generic summary print.summary method. x (g)susie summary.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/summary.gsusie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize G-SuSiE Fit. — summary.gsusie","text":"list containing data frame variables data frame credible sets.","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/update_each_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Update each single effect at a time — update_each_effect","title":"Update each single effect at a time — update_each_effect","text":"Update single effect time","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/update_each_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update each single effect at a time — update_each_effect","text":"","code":"update_each_effect(   X,   y,   gs,   model,   estimate_prior_variance = FALSE,   estimate_prior_method = \"optim\",   check_null_threshold = 0,   abnormal_proportion = 0.5,   robust_estimation = FALSE,   robust_method = \"simple\",   simple_outlier_fraction = 0.01,   simple_outlier_thres = NULL,   robust_tuning_method = NULL )"},{"path":"https://ymyuan98.github.io/gsusie/reference/update_each_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update each single effect at a time — update_each_effect","text":"X n p matrix regression variables. y n vector response variable. gs GSuSiE fit. model list containing functions required specific generalized linear model. estimate_prior_variance Boolean. TRUE, coefficient prior variance estimated coef_prior_variance used initial value optimization (provided). FALSE, prior variance maxL effects fixed determined value supplied coef_prior_variance. estimate_prior_method method used estimating prior variance. estimate_prior_method=\"simple\" used, likelihood specified prior variance compared likelihood variance zero, setting larger likelihood retained. check_null_threshold prior variance estimated, compare estimated null, set prior variance zero unless log-likelihood using estimate larger threshold amount. abnormal_proportion value 0 1. number detected abnormal subjects exceeds \\(abnormal_proportion * nrow(X)\\), stop fitting model. robust_estimation robust_estimation=TRUE, robust estimation method applied coefficient estimation. robust_method robust_method= \"simple\", outliers defined simple_outlier_fraction simple_outlier_thres simply removed iteration. robust_method=\"huber\", Huber weights additionally multiplied pseudo-weights iteration. robust_method = \"bisquare\", (Tukey's) bisquare weights additionally multipled pseudo-weights iteration. simple_outlier_fraction value 0 1, indicating fraction outliers: define simple_outlier_fraction percent subjects highest absolute values (inverse pseudo-variance) outliers. default, simple_outlier_fraction=NULL set outlier fraction. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". simple_outlier_thres real value, indicating outliers whose inverse pseudo-variance exceed threshold removed current iteration. Either simple_outlier_fraction simple_outlier_thres specified robust_method = \"simple\". robust_tuning_method robust_tuning_method = \"M\", M-estimation performed. robust_tuning_method = \"S\", S-estimation performed. argument specifies tuning method, .e., method defining outliers iteration, applying Huber Bisquare reweighting method (robust_method = \"huber\" robust_method = \"bisquare\").","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/warning_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function to display warning messages as they occur — warning_message","title":"Utility function to display warning messages as they occur — warning_message","text":"Utility function display warning messages occur","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/warning_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function to display warning messages as they occur — warning_message","text":"","code":"warning_message(..., style = c(\"warning\", \"hint\"))"},{"path":"https://ymyuan98.github.io/gsusie/reference/warning_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function to display warning messages as they occur — warning_message","text":"... warning message style either \"warning\" \"hint\"","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/weighted_single_effect_regresion.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted single effect regression — weighted_single_effect_regresion","title":"Weighted single effect regression — weighted_single_effect_regresion","text":"WSER function compute posterior distribution regression coefficients WSER model. Reference: https://github.com/stephenslab/susieR/blob/master/R/single_effect_regression.R","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/weighted_single_effect_regresion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted single effect regression — weighted_single_effect_regresion","text":"","code":"weighted_single_effect_regresion(   y,   X,   weights = 1,   prior_inclusion_prob = NULL,   coef_prior_variance = 1,   optimize_V = c(\"none\", \"optim\", \"EM\", \"simple\"),   check_null_threshold = 0 )"},{"path":"https://ymyuan98.github.io/gsusie/reference/weighted_single_effect_regresion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted single effect regression — weighted_single_effect_regresion","text":"weights (n x 1) array, weights subject. generalized linear model using iterative reweighted least squared approach, \\(weights = exp(-logw2)\\). optimize_V optimization method use fitting prior variance. check_null_threshold Scalar specifying threshold log-scale compare likelihood current estimate zero (null).","code":""},{"path":"https://ymyuan98.github.io/gsusie/reference/weighted_single_effect_regresion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted single effect regression — weighted_single_effect_regresion","text":"list following elements: alpha Vector posterior inclusion probabilities; alpha[] posterior probability ith coefficient non-zero. mu Vector posterior means (conditional inclusion). mu2 Vector posterior second moments (conditional inclusion). sigma12 Vector posterior variance (conditional inclusion). logABF Vector log asymptotic Bayes factor variable. logABF_model Log asymptotic Bayes factor weighted single effect regression. V Prior variance (optimization optimize_V != \"none\").","code":""}]
